{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing, Augmenting and Splitting the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.datasets` has numpy arrays but these have each RGB values, which lie between 0 and 255.   \n",
    "\n",
    "* The usual matrix representation has each pixel with a value between 0 and 1, with 0 being white and 1 being black, and to get this we divide by 255.\n",
    "\n",
    "* I've split the training set into 2 parts of 30k images and performed the following augmentations:\n",
    "    - Adding random noise \n",
    "    - Shifting the images by 20%\n",
    "    - Rotated images randomly between 10 and -10 degrees\n",
    "    - Flipped images laterally, with a 50% chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of datasets:\n",
      "x_train: (784, 120000)\n",
      "y_train: (10, 120000)\n",
      "x_dev: (5000, 28, 28)\n",
      "y_dev: (10, 5000)\n",
      "x_test: (5000, 28, 28)\n",
      "y_test: (10, 5000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "y_train_encoded = np.array(pd.get_dummies(y_train, dtype=int))\n",
    "y_test_encoded = np.array(pd.get_dummies(y_test, dtype=int))\n",
    "\n",
    "\n",
    "x_dev, x_test, y_dev, y_test = train_test_split(x_test, y_test_encoded, test_size=0.5, random_state=23)\n",
    "\n",
    "\n",
    "seq1 = iaa.Sequential([\n",
    "    iaa.AdditiveGaussianNoise(scale=0.05*255),\n",
    "    iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
    "])\n",
    "\n",
    "seq2 = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-10, 10)),\n",
    "    iaa.Fliplr(0.50)\n",
    "])\n",
    "\n",
    "\n",
    "x_train_sub_1 = seq1.augment_images(x_train[:30000])\n",
    "x_train_sub_2 = seq2.augment_images(x_train[30000:])\n",
    "\n",
    "\n",
    "x_train_mod = np.concatenate((x_train_sub_1, x_train_sub_2), axis=0) / 255.0\n",
    "y_train_mod = np.concatenate((y_train_encoded[:30000], y_train_encoded[:30000]), axis=0).T\n",
    "\n",
    "\n",
    "x_train_mod = x_train_mod.reshape(-1, 28*28).T\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float') / 255.0\n",
    "x_dev = x_dev.astype('float') / 255.0\n",
    "x_test = x_test.astype('float') / 255.0\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(-1, 28*28).T\n",
    "\n",
    "\n",
    "x_train = np.concatenate((x_train, x_train_mod), axis=1)\n",
    "y_train = np.concatenate((y_train_encoded.T, y_train_mod), axis=1)\n",
    "\n",
    "y_dev=y_dev.T\n",
    "y_test=y_test.T\n",
    "\n",
    "\n",
    "print(\"Shapes of datasets:\")\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"x_dev:\", x_dev.shape)\n",
    "print(\"y_dev:\", y_dev.shape)\n",
    "print(\"x_test:\", x_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 1 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(z,str):\n",
    "    if str==\"relu\":\n",
    "        return np.maximum(z,0)\n",
    "    elif str==\"tanh\":\n",
    "        return np.tanh(z)\n",
    "    elif str==\"softmax\":\n",
    "        return(np.exp(z))/np.sum(np.exp(z),axis=0,keepdims=True)\n",
    "\n",
    "def tanh_grad(z):\n",
    "    return (1-np.power(np.tanh(z),2))\n",
    "\n",
    "def relu_grad(z):\n",
    "    return np.array(z>0,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising Parameters:\n",
    "We have:\n",
    "* 1 input layer\n",
    "* 2 hidden layers\n",
    "* 1 output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_initialization(l_o,l_i):\n",
    "    return np.random.randn(l_o,l_i)*0.01\n",
    "\n",
    "def glorot_initialization(l_o, l_i):\n",
    "    return np.random.randn(l_o, l_i) * np.sqrt(1 / l_i)\n",
    "\n",
    "def he_initialization(l_o,l_i):\n",
    "    return np.random.randn(l_o, l_i) * np.sqrt(2 / l_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(layer_dims):\n",
    "    params = {}\n",
    "    \n",
    "    for l in range(1, len(layer_dims)):\n",
    "        W = he_initialization(layer_dims[l],layer_dims[l-1])\n",
    "        B = np.zeros((layer_dims[l], 1))\n",
    "        params[\"W\" + str(l)] = W\n",
    "        params[\"B\" + str(l)] = B\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function: (Average Cross-Entropy Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(y_hat, y):\n",
    " return -(1/y.shape[1])*(np.sum(y*np.log(y_hat)))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward and Backward Propagations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, params):\n",
    "    cache = {}\n",
    "    A = x  \n",
    "   \n",
    "    for l in range(1, 4): \n",
    "        \n",
    "        W = params[\"W\" + str(l)]\n",
    "        B = params[\"B\" + str(l)]\n",
    "        \n",
    "        Z = np.dot(W, A) + B\n",
    "        \n",
    "        if l == 1:\n",
    "            A=activation_function(Z,\"relu\")\n",
    "        elif l == 2:\n",
    "            A=activation_function(Z,\"tanh\")\n",
    "        else:\n",
    "            A=activation_function(Z,\"softmax\")\n",
    "        \n",
    "        \n",
    "        cache[\"Z\" + str(l)] = Z\n",
    "        cache[\"A\" + str(l)] = A\n",
    "    \n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(x, y, cache, params):\n",
    "    \n",
    "    W3 = params['W3']\n",
    "    W2 = params['W2']\n",
    "    \n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    A3 = cache['A3']\n",
    "    \n",
    "    m = x.shape[1]\n",
    "    \n",
    "    dZ3 = (A3 - y)\n",
    "    dW3 = (1/m)*np.dot(dZ3, A2.T)\n",
    "    dB3 = (1/m)*np.sum(dZ3, axis = 1, keepdims = True)\n",
    "    \n",
    "    dZ2 = (1/m)*np.dot(W3.T, dZ3)*tanh_grad(A2)\n",
    "    dW2 = (1/m)*np.dot(dZ2, A1.T)\n",
    "    dB2 = (1/m)*np.sum(dZ2, axis = 1, keepdims = True)\n",
    "\n",
    "    dZ1 = (1/m)*np.dot(W2.T, dZ2)*relu_grad(A1)\n",
    "    dW1 = (1/m)*np.dot(dZ1, x.T)\n",
    "    dB1 = (1/m)*np.sum(dZ1, axis = 1, keepdims = True)\n",
    "    \n",
    "    grads = {\n",
    "        \"dW1\" : dW1,\n",
    "        \"dB1\" : dB1,\n",
    "        \"dW2\" : dW2,\n",
    "        \"dB2\" : dB2,\n",
    "        \"dW3\" : dW3,\n",
    "        \"dB3\" : dB3\n",
    "    }\n",
    "    \n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_desc(alpha, params, grads):\n",
    "\n",
    "    for l in range(1, 4):\n",
    "        W = params[\"W\" + str(l)]\n",
    "        b = params[\"B\" + str(l)]\n",
    "        \n",
    "        dW = grads[\"dW\" + str(l)]\n",
    "        db = grads[\"dB\" + str(l)]\n",
    "        \n",
    "        # Update parameters using gradient descent\n",
    "        W -= alpha * dW\n",
    "        b -= alpha * db\n",
    "        \n",
    "        # Update params dictionary\n",
    "        params[\"W\" + str(l)] = W\n",
    "        params[\"B\" + str(l)] = b\n",
    "\n",
    "    return params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(x,y,layer_dims,alpha,iterations):\n",
    "    \n",
    "    params=init_params(layer_dims)\n",
    "    cost_val=[0]*iterations\n",
    "\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        cache=forward_prop(x,params)\n",
    "        \n",
    "        #add to cost values list \n",
    "        cost_val[i]=cost_function(cache['A3'],y)\n",
    "        \n",
    "        #perform backprop, find gradients\n",
    "        grads=back_prop(x,y,cache,params)\n",
    "        \n",
    "        #update parameters\n",
    "        params=grad_desc(alpha,params,grads)\n",
    "        \n",
    "        \n",
    "        print(f\"The cost at iteration {i} is: {cost_val[i]}\")        \n",
    "    \n",
    "    return params,cost_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost at iteration 0 is: 2.423754126746061\n",
      "The cost at iteration 1 is: 2.275683020622694\n",
      "The cost at iteration 2 is: 2.1851704350466203\n",
      "The cost at iteration 3 is: 2.1189123883285017\n",
      "The cost at iteration 4 is: 2.06039095569793\n",
      "The cost at iteration 5 is: 2.0086655427155247\n",
      "The cost at iteration 6 is: 1.9629465493712066\n",
      "The cost at iteration 7 is: 1.9225133385145745\n",
      "The cost at iteration 8 is: 1.8867071130327002\n",
      "The cost at iteration 9 is: 1.8549372581899557\n",
      "The cost at iteration 10 is: 1.8266810471613635\n",
      "The cost at iteration 11 is: 1.8014808722989288\n",
      "The cost at iteration 12 is: 1.778939033301322\n",
      "The cost at iteration 13 is: 1.7587116415607082\n",
      "The cost at iteration 14 is: 1.7405022679714321\n",
      "The cost at iteration 15 is: 1.724055825320036\n",
      "The cost at iteration 16 is: 1.7091529272828647\n",
      "The cost at iteration 17 is: 1.695604836023703\n",
      "The cost at iteration 18 is: 1.683249025146906\n",
      "The cost at iteration 19 is: 1.671945335207836\n",
      "The cost at iteration 20 is: 1.6615726737069458\n",
      "The cost at iteration 21 is: 1.6520262003692823\n",
      "The cost at iteration 22 is: 1.6432149363451685\n",
      "The cost at iteration 23 is: 1.6350597386266799\n",
      "The cost at iteration 24 is: 1.6274915861225463\n",
      "The cost at iteration 25 is: 1.620450129961695\n",
      "The cost at iteration 26 is: 1.6138824668496297\n",
      "The cost at iteration 27 is: 1.6077421002134704\n",
      "The cost at iteration 28 is: 1.6019880592159854\n",
      "The cost at iteration 29 is: 1.5965841504161737\n",
      "The cost at iteration 30 is: 1.591498320904615\n",
      "The cost at iteration 31 is: 1.58670211519018\n",
      "The cost at iteration 32 is: 1.5821702110239648\n",
      "The cost at iteration 33 is: 1.5778800217857596\n",
      "The cost at iteration 34 is: 1.5738113550952642\n",
      "The cost at iteration 35 is: 1.5699461190066997\n",
      "The cost at iteration 36 is: 1.5662680685560608\n",
      "The cost at iteration 37 is: 1.5627625866023938\n",
      "The cost at iteration 38 is: 1.559416493878635\n",
      "The cost at iteration 39 is: 1.5562178839773722\n",
      "The cost at iteration 40 is: 1.5531559796708412\n",
      "The cost at iteration 41 is: 1.5502210075260687\n",
      "The cost at iteration 42 is: 1.5474040882446143\n",
      "The cost at iteration 43 is: 1.544697140548049\n",
      "The cost at iteration 44 is: 1.5420927967582614\n",
      "The cost at iteration 45 is: 1.5395843284968371\n",
      "The cost at iteration 46 is: 1.5371655811590073\n",
      "The cost at iteration 47 is: 1.5348309160125575\n",
      "The cost at iteration 48 is: 1.532575158936487\n",
      "The cost at iteration 49 is: 1.530393554953359\n",
      "The cost at iteration 50 is: 1.528281727827215\n",
      "The cost at iteration 51 is: 1.5262356440990665\n",
      "The cost at iteration 52 is: 1.5242515810173207\n",
      "The cost at iteration 53 is: 1.5223260978931736\n",
      "The cost at iteration 54 is: 1.5204560104732847\n",
      "The cost at iteration 55 is: 1.5186383679752058\n",
      "The cost at iteration 56 is: 1.5168704324768871\n",
      "The cost at iteration 57 is: 1.5151496603908\n",
      "The cost at iteration 58 is: 1.5134736857871793\n",
      "The cost at iteration 59 is: 1.5118403053601033\n",
      "The cost at iteration 60 is: 1.5102474648554443\n",
      "The cost at iteration 61 is: 1.5086932468016827\n",
      "The cost at iteration 62 is: 1.5071758594035811\n",
      "The cost at iteration 63 is: 1.5056936264752903\n",
      "The cost at iteration 64 is: 1.5042449783039085\n",
      "The cost at iteration 65 is: 1.5028284433470769\n",
      "The cost at iteration 66 is: 1.5014426406792067\n",
      "The cost at iteration 67 is: 1.5000862731106026\n",
      "The cost at iteration 68 is: 1.4987581209121714\n",
      "The cost at iteration 69 is: 1.4974570360858162\n",
      "The cost at iteration 70 is: 1.496181937127218\n",
      "The cost at iteration 71 is: 1.4949318042333617\n",
      "The cost at iteration 72 is: 1.493705674912347\n",
      "The cost at iteration 73 is: 1.4925026399574162\n",
      "The cost at iteration 74 is: 1.4913218397511836\n",
      "The cost at iteration 75 is: 1.490162460869505\n",
      "The cost at iteration 76 is: 1.4890237329575946\n",
      "The cost at iteration 77 is: 1.4879049258537373\n",
      "The cost at iteration 78 is: 1.4868053469384257\n",
      "The cost at iteration 79 is: 1.485724338688958\n",
      "The cost at iteration 80 is: 1.4846612764214706\n",
      "The cost at iteration 81 is: 1.4836155662041373\n",
      "The cost at iteration 82 is: 1.4825866429268426\n",
      "The cost at iteration 83 is: 1.4815739685140294\n",
      "The cost at iteration 84 is: 1.4805770302686503\n",
      "The cost at iteration 85 is: 1.479595339336327\n",
      "The cost at iteration 86 is: 1.478628429279791\n",
      "The cost at iteration 87 is: 1.4776758547545963\n",
      "The cost at iteration 88 is: 1.4767371902779176\n",
      "The cost at iteration 89 is: 1.4758120290829915\n",
      "The cost at iteration 90 is: 1.4748999820523923\n",
      "The cost at iteration 91 is: 1.4740006767239606\n",
      "The cost at iteration 92 is: 1.4731137563637529\n",
      "The cost at iteration 93 is: 1.4722388791007996\n",
      "The cost at iteration 94 is: 1.4713757171190238\n",
      "The cost at iteration 95 is: 1.4705239559019379\n",
      "The cost at iteration 96 is: 1.4696832935262112\n",
      "The cost at iteration 97 is: 1.4688534400004543\n",
      "The cost at iteration 98 is: 1.4680341166459245\n",
      "The cost at iteration 99 is: 1.4672250555160748\n",
      "The cost at iteration 100 is: 1.4664259988521595\n",
      "The cost at iteration 101 is: 1.4656366985723197\n",
      "The cost at iteration 102 is: 1.46485691579177\n",
      "The cost at iteration 103 is: 1.4640864203719133\n",
      "The cost at iteration 104 is: 1.463324990496349\n",
      "The cost at iteration 105 is: 1.462572412271973\n",
      "The cost at iteration 106 is: 1.4618284793533787\n",
      "The cost at iteration 107 is: 1.4610929925890548\n",
      "The cost at iteration 108 is: 1.4603657596878696\n",
      "The cost at iteration 109 is: 1.4596465949045137\n",
      "The cost at iteration 110 is: 1.4589353187426455\n",
      "The cost at iteration 111 is: 1.458231757674582\n",
      "The cost at iteration 112 is: 1.4575357438764605\n",
      "The cost at iteration 113 is: 1.4568471149778843\n",
      "The cost at iteration 114 is: 1.456165713825127\n",
      "The cost at iteration 115 is: 1.4554913882570253\n",
      "The cost at iteration 116 is: 1.454823990892804\n",
      "The cost at iteration 117 is: 1.4541633789310375\n",
      "The cost at iteration 118 is: 1.4535094139591147\n",
      "The cost at iteration 119 is: 1.4528619617725322\n",
      "The cost at iteration 120 is: 1.4522208922034399\n",
      "The cost at iteration 121 is: 1.4515860789578627\n",
      "The cost at iteration 122 is: 1.4509573994611193\n",
      "The cost at iteration 123 is: 1.4503347347109026\n",
      "The cost at iteration 124 is: 1.4497179691376245\n",
      "The cost at iteration 125 is: 1.4491069904715645\n",
      "The cost at iteration 126 is: 1.4485016896164566\n",
      "The cost at iteration 127 is: 1.4479019605291255\n",
      "The cost at iteration 128 is: 1.4473077001048547\n",
      "The cost at iteration 129 is: 1.4467188080681328\n",
      "The cost at iteration 130 is: 1.4461351868685102\n",
      "The cost at iteration 131 is: 1.4455567415812616\n",
      "The cost at iteration 132 is: 1.444983379812595\n",
      "The cost at iteration 133 is: 1.4444150116091723\n",
      "The cost at iteration 134 is: 1.4438515493716988\n",
      "The cost at iteration 135 is: 1.4432929077723506\n",
      "The cost at iteration 136 is: 1.4427390036758678\n",
      "The cost at iteration 137 is: 1.4421897560640984\n",
      "The cost at iteration 138 is: 1.441645085963803\n",
      "The cost at iteration 139 is: 1.4411049163775909\n",
      "The cost at iteration 140 is: 1.4405691722177778\n",
      "The cost at iteration 141 is: 1.4400377802430493\n",
      "The cost at iteration 142 is: 1.439510668997784\n",
      "The cost at iteration 143 is: 1.4389877687538788\n",
      "The cost at iteration 144 is: 1.43846901145499\n",
      "The cost at iteration 145 is: 1.4379543306630338\n",
      "The cost at iteration 146 is: 1.4374436615068689\n",
      "The cost at iteration 147 is: 1.4369369406330168\n",
      "The cost at iteration 148 is: 1.4364341061583614\n",
      "The cost at iteration 149 is: 1.435935097624706\n",
      "The cost at iteration 150 is: 1.4354398559551071\n",
      "The cost at iteration 151 is: 1.4349483234119007\n",
      "The cost at iteration 152 is: 1.4344604435563526\n",
      "The cost at iteration 153 is: 1.43397616120983\n",
      "The cost at iteration 154 is: 1.4334954224164627\n",
      "The cost at iteration 155 is: 1.4330181744071833\n",
      "The cost at iteration 156 is: 1.4325443655651235\n",
      "The cost at iteration 157 is: 1.4320739453922748\n",
      "The cost at iteration 158 is: 1.4316068644773772\n",
      "The cost at iteration 159 is: 1.4311430744649687\n",
      "The cost at iteration 160 is: 1.4306825280255517\n",
      "The cost at iteration 161 is: 1.4302251788268205\n",
      "The cost at iteration 162 is: 1.4297709815059232\n",
      "The cost at iteration 163 is: 1.4293198916426773\n",
      "The cost at iteration 164 is: 1.4288718657337351\n",
      "The cost at iteration 165 is: 1.428426861167639\n",
      "The cost at iteration 166 is: 1.4279848362007357\n",
      "The cost at iteration 167 is: 1.4275457499339028\n",
      "The cost at iteration 168 is: 1.4271095622900762\n",
      "The cost at iteration 169 is: 1.4266762339925185\n",
      "The cost at iteration 170 is: 1.4262457265438193\n",
      "The cost at iteration 171 is: 1.4258180022055875\n",
      "The cost at iteration 172 is: 1.4253930239788097\n",
      "The cost at iteration 173 is: 1.424970755584851\n",
      "The cost at iteration 174 is: 1.424551161447059\n",
      "The cost at iteration 175 is: 1.42413420667298\n",
      "The cost at iteration 176 is: 1.4237198570371186\n",
      "The cost at iteration 177 is: 1.4233080789642567\n",
      "The cost at iteration 178 is: 1.422898839513291\n",
      "The cost at iteration 179 is: 1.4224921063615783\n",
      "The cost at iteration 180 is: 1.4220878477897607\n",
      "The cost at iteration 181 is: 1.4216860326670608\n",
      "The cost at iteration 182 is: 1.4212866304370297\n",
      "The cost at iteration 183 is: 1.4208896111037121\n",
      "The cost at iteration 184 is: 1.4204949452182511\n",
      "The cost at iteration 185 is: 1.4201026038658724\n",
      "The cost at iteration 186 is: 1.4197125586532682\n",
      "The cost at iteration 187 is: 1.419324781696349\n",
      "The cost at iteration 188 is: 1.418939245608353\n",
      "The cost at iteration 189 is: 1.4185559234883087\n",
      "The cost at iteration 190 is: 1.4181747889098197\n",
      "The cost at iteration 191 is: 1.417795815910186\n",
      "The cost at iteration 192 is: 1.4174189789798255\n",
      "The cost at iteration 193 is: 1.4170442530519978\n",
      "The cost at iteration 194 is: 1.4166716134928257\n",
      "The cost at iteration 195 is: 1.416301036091581\n",
      "The cost at iteration 196 is: 1.4159324970512588\n",
      "The cost at iteration 197 is: 1.4155659729793966\n",
      "The cost at iteration 198 is: 1.415201440879161\n",
      "The cost at iteration 199 is: 1.4148388781406667\n",
      "The cost at iteration 200 is: 1.414478262532537\n",
      "The cost at iteration 201 is: 1.4141195721936892\n",
      "The cost at iteration 202 is: 1.4137627856253445\n",
      "The cost at iteration 203 is: 1.4134078816832465\n",
      "The cost at iteration 204 is: 1.4130548395700977\n",
      "The cost at iteration 205 is: 1.412703638828177\n",
      "The cost at iteration 206 is: 1.4123542593321692\n",
      "The cost at iteration 207 is: 1.4120066812821688\n",
      "The cost at iteration 208 is: 1.4116608851968746\n",
      "The cost at iteration 209 is: 1.4113168519069514\n",
      "The cost at iteration 210 is: 1.4109745625485737\n",
      "The cost at iteration 211 is: 1.4106339985571217\n",
      "The cost at iteration 212 is: 1.410295141661045\n",
      "The cost at iteration 213 is: 1.4099579738758783\n",
      "The cost at iteration 214 is: 1.4096224774984123\n",
      "The cost at iteration 215 is: 1.409288635101001\n",
      "The cost at iteration 216 is: 1.408956429526022\n",
      "The cost at iteration 217 is: 1.4086258438804622\n",
      "The cost at iteration 218 is: 1.4082968615306481\n",
      "The cost at iteration 219 is: 1.4079694660970967\n",
      "The cost at iteration 220 is: 1.4076436414494937\n",
      "The cost at iteration 221 is: 1.407319371701796\n",
      "The cost at iteration 222 is: 1.4069966412074508\n",
      "The cost at iteration 223 is: 1.4066754345547297\n",
      "The cost at iteration 224 is: 1.4063557365621715\n",
      "The cost at iteration 225 is: 1.406037532274138\n",
      "The cost at iteration 226 is: 1.4057208069564764\n",
      "The cost at iteration 227 is: 1.4054055460922645\n",
      "The cost at iteration 228 is: 1.4050917353776928\n",
      "The cost at iteration 229 is: 1.404779360718006\n",
      "The cost at iteration 230 is: 1.4044684082235563\n",
      "The cost at iteration 231 is: 1.4041588642059473\n",
      "The cost at iteration 232 is: 1.4038507151742643\n",
      "The cost at iteration 233 is: 1.4035439478313874\n",
      "The cost at iteration 234 is: 1.4032385490703996\n",
      "The cost at iteration 235 is: 1.402934505971057\n",
      "The cost at iteration 236 is: 1.4026318057963623\n",
      "The cost at iteration 237 is: 1.4023304359891966\n",
      "The cost at iteration 238 is: 1.402030384169037\n",
      "The cost at iteration 239 is: 1.4017316381287404\n",
      "The cost at iteration 240 is: 1.4014341858314074\n",
      "The cost at iteration 241 is: 1.401138015407303\n",
      "The cost at iteration 242 is: 1.400843115150859\n",
      "The cost at iteration 243 is: 1.4005494735177335\n",
      "The cost at iteration 244 is: 1.4002570791219313\n",
      "The cost at iteration 245 is: 1.3999659207329993\n",
      "The cost at iteration 246 is: 1.399675987273273\n",
      "The cost at iteration 247 is: 1.3993872678151782\n",
      "The cost at iteration 248 is: 1.3990997515786057\n",
      "The cost at iteration 249 is: 1.3988134279283282\n",
      "The cost at iteration 250 is: 1.3985282863714776\n",
      "The cost at iteration 251 is: 1.3982443165550775\n",
      "The cost at iteration 252 is: 1.3979615082636214\n",
      "The cost at iteration 253 is: 1.3976798514167124\n",
      "The cost at iteration 254 is: 1.3973993360667385\n",
      "The cost at iteration 255 is: 1.3971199523966078\n",
      "The cost at iteration 256 is: 1.3968416907175294\n",
      "The cost at iteration 257 is: 1.3965645414668277\n",
      "The cost at iteration 258 is: 1.3962884952058274\n",
      "The cost at iteration 259 is: 1.3960135426177513\n",
      "The cost at iteration 260 is: 1.3957396745056834\n",
      "The cost at iteration 261 is: 1.3954668817905644\n",
      "The cost at iteration 262 is: 1.395195155509229\n",
      "The cost at iteration 263 is: 1.3949244868124844\n",
      "The cost at iteration 264 is: 1.3946548669632288\n",
      "The cost at iteration 265 is: 1.3943862873346013\n",
      "The cost at iteration 266 is: 1.3941187394081735\n",
      "The cost at iteration 267 is: 1.393852214772181\n",
      "The cost at iteration 268 is: 1.3935867051197806\n",
      "The cost at iteration 269 is: 1.3933222022473486\n",
      "The cost at iteration 270 is: 1.3930586980528141\n",
      "The cost at iteration 271 is: 1.392796184534019\n",
      "The cost at iteration 272 is: 1.3925346537871115\n",
      "The cost at iteration 273 is: 1.3922740980049793\n",
      "The cost at iteration 274 is: 1.3920145094756984\n",
      "The cost at iteration 275 is: 1.3917558805810255\n",
      "The cost at iteration 276 is: 1.3914982037949128\n",
      "The cost at iteration 277 is: 1.3912414716820507\n",
      "The cost at iteration 278 is: 1.3909856768964448\n",
      "The cost at iteration 279 is: 1.3907308121800135\n",
      "The cost at iteration 280 is: 1.3904768703612107\n",
      "The cost at iteration 281 is: 1.3902238443536845\n",
      "The cost at iteration 282 is: 1.389971727154952\n",
      "The cost at iteration 283 is: 1.3897205118451044\n",
      "The cost at iteration 284 is: 1.3894701915855299\n",
      "The cost at iteration 285 is: 1.3892207596176724\n",
      "The cost at iteration 286 is: 1.3889722092617955\n",
      "The cost at iteration 287 is: 1.3887245339157923\n",
      "The cost at iteration 288 is: 1.388477727053992\n",
      "The cost at iteration 289 is: 1.3882317822260117\n",
      "The cost at iteration 290 is: 1.3879866930556177\n",
      "The cost at iteration 291 is: 1.3877424532395983\n",
      "The cost at iteration 292 is: 1.3874990565466832\n",
      "The cost at iteration 293 is: 1.3872564968164587\n",
      "The cost at iteration 294 is: 1.387014767958311\n",
      "The cost at iteration 295 is: 1.3867738639503933\n",
      "The cost at iteration 296 is: 1.3865337788386018\n",
      "The cost at iteration 297 is: 1.3862945067355825\n",
      "The cost at iteration 298 is: 1.3860560418197405\n",
      "The cost at iteration 299 is: 1.385818378334284\n",
      "The cost at iteration 300 is: 1.385581510586268\n",
      "The cost at iteration 301 is: 1.385345432945672\n",
      "The cost at iteration 302 is: 1.3851101398444823\n",
      "The cost at iteration 303 is: 1.3848756257757904\n",
      "The cost at iteration 304 is: 1.3846418852929157\n",
      "The cost at iteration 305 is: 1.3844089130085409\n",
      "The cost at iteration 306 is: 1.3841767035938495\n",
      "The cost at iteration 307 is: 1.3839452517777053\n",
      "The cost at iteration 308 is: 1.3837145523458163\n",
      "The cost at iteration 309 is: 1.3834846001399328\n",
      "The cost at iteration 310 is: 1.3832553900570568\n",
      "The cost at iteration 311 is: 1.3830269170486522\n",
      "The cost at iteration 312 is: 1.3827991761198892\n",
      "The cost at iteration 313 is: 1.382572162328882\n",
      "The cost at iteration 314 is: 1.3823458707859564\n",
      "The cost at iteration 315 is: 1.3821202966529098\n",
      "The cost at iteration 316 is: 1.3818954351423105\n",
      "The cost at iteration 317 is: 1.38167128151678\n",
      "The cost at iteration 318 is: 1.3814478310883116\n",
      "The cost at iteration 319 is: 1.3812250792175855\n",
      "The cost at iteration 320 is: 1.381003021313298\n",
      "The cost at iteration 321 is: 1.3807816528315109\n",
      "The cost at iteration 322 is: 1.3805609692749998\n",
      "The cost at iteration 323 is: 1.3803409661926198\n",
      "The cost at iteration 324 is: 1.3801216391786795\n",
      "The cost at iteration 325 is: 1.3799029838723307\n",
      "The cost at iteration 326 is: 1.3796849959569535\n",
      "The cost at iteration 327 is: 1.3794676711595732\n",
      "The cost at iteration 328 is: 1.3792510052502698\n",
      "The cost at iteration 329 is: 1.3790349940416022\n",
      "The cost at iteration 330 is: 1.3788196333880436\n",
      "The cost at iteration 331 is: 1.3786049191854217\n",
      "The cost at iteration 332 is: 1.378390847370379\n",
      "The cost at iteration 333 is: 1.378177413919824\n",
      "The cost at iteration 334 is: 1.377964614850406\n",
      "The cost at iteration 335 is: 1.377752446217995\n",
      "The cost at iteration 336 is: 1.3775409041171638\n",
      "The cost at iteration 337 is: 1.377329984680685\n",
      "The cost at iteration 338 is: 1.3771196840790394\n",
      "The cost at iteration 339 is: 1.3769099985199145\n",
      "The cost at iteration 340 is: 1.376700924247736\n",
      "The cost at iteration 341 is: 1.3764924575431838\n",
      "The cost at iteration 342 is: 1.3762845947227371\n",
      "The cost at iteration 343 is: 1.3760773321382025\n",
      "The cost at iteration 344 is: 1.3758706661762716\n",
      "The cost at iteration 345 is: 1.3756645932580738\n",
      "The cost at iteration 346 is: 1.3754591098387339\n",
      "The cost at iteration 347 is: 1.3752542124069498\n",
      "The cost at iteration 348 is: 1.3750498974845635\n",
      "The cost at iteration 349 is: 1.3748461616261411\n"
     ]
    }
   ],
   "source": [
    "L1=784\n",
    "L2=784\n",
    "layer_dims=[x_train.shape[0],L1,L2,y_train.shape[0]]\n",
    "\n",
    "\n",
    "params,cost_values=NN(x_train,y_train,layer_dims,0.2,350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_hat_func(x,params):\n",
    "    \n",
    "    cache=forward_prop(x,params)\n",
    "\n",
    "    y_hat=cache['A3']\n",
    "    y_hat=np.argmax(y_hat,0)    \n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dev Accuracy Score: 90.32%\n",
      "Dev Precision Score:90.37132589351639% \n",
      "Dev Recall Score:90.32\n",
      "Dev f1 Score:90.25941640636742\n",
      "\n",
      "\n",
      "Test Accuracy Score: 90.62%\n",
      "Test Precision Score:90.63128007476033% \n",
      "Test Recall Score:90.62\n",
      "Test f1 Score:90.56712978642929\n"
     ]
    }
   ],
   "source": [
    "x_test=x_test.reshape(5000,-1).T\n",
    "x_dev=x_dev.reshape(5000,-1).T\n",
    "\n",
    "y_hat_dev=y_hat_func(x_dev,params)\n",
    "y_hat_test=y_hat_func(x_test,params)\n",
    "\n",
    "print(f\"\\n\\nDev Accuracy Score: {accuracy_score(np.argmax(y_dev,0),y_hat_dev)*100}%\")\n",
    "print(f\"Dev Precision Score:{precision_score(np.argmax(y_dev,0),y_hat_dev,average='weighted')*100}% \")\n",
    "print(f\"Dev Recall Score:{recall_score(np.argmax(y_dev,0),y_hat_dev,average='weighted')*100}\")\n",
    "print(f\"Dev f1 Score:{f1_score(np.argmax(y_dev,0),y_hat_dev,average='weighted')*100}\")\n",
    "\n",
    "print(f\"\\n\\nTest Accuracy Score: {accuracy_score(np.argmax(y_test,0),y_hat_test)*100}%\")\n",
    "print(f\"Test Precision Score:{precision_score(np.argmax(y_test,0),y_hat_test,average='weighted')*100}% \")\n",
    "print(f\"Test Recall Score:{recall_score(np.argmax(y_test,0),y_hat_test,average='weighted')*100}\")\n",
    "print(f\"Test f1 Score:{f1_score(np.argmax(y_test,0),y_hat_test,average='weighted')*100}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2c313ce7f0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
